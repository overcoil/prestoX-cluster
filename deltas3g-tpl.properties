#
# deltas3g.properties
# 
# Configuration for working with tables defined inside AWS Glue
#

# PrestoDB's connector is named "delta" vs Trino's "delta-lake" 
#connector.name=delta
connector.name=delta-lake

#
# Trino ref for Glue configuration: 
#    https://trino.io/docs/current/connector/hive.html#aws-glue-catalog-configuration-properties
#
hive.metastore=glue
hive.metastore.glue.region=us-west-2

#hive.metastore.glue.endpoint-url=https://glue.us-west-2.amazonaws.com
#hive.metastore.glue.max-connections=5
#hive.metastore.glue.max-error-retries=10
#hive.metastore.glue.default-warehouse-dir

# The metastore needs a key for its own use
# Fill in taking care to not push this upstream!
hive.metastore.glue.aws-access-key=ZZ-AWS-ACCESS-KEY-ID
hive.metastore.glue.aws-secret-key=ZZ-AWS-SECRET-ACCESS-KEY

# Fill in 
hive.metastore.glue.catalogid=ZZ-AWS-USER-ID

# this is the ARN for the created role
# TODO: Is this needed if Trino is running in EC2?
# hive.metastore.glue.iam-role=arn:aws:iam::ZZ-AWS-ACCOUNT-ID:role/dev_db_c3_role-sep

#hive.metastore.glue.external-id
#hive.metastore.glue.partitions-segments=5
#hive.metastore.glue.get-partition-threads=20
#hive.metastore.glue.read-statistics-threads=5
#hive.metastore.glue.write-statistics-threads=5

# Using Delta table in s3
#  for Trino: refer to presto-hive/src/main/java/io/prestosql/plugin/hive/s3/HiveS3Config.java
#  for Presto: refer to presto-hive/src/main/java/com/facebook/presto/hive/s3/HiveS3Config.java

hive.s3.endpoint=https://s3.us-west-2.amazonaws.com

# this is for the connector itself to reach S3; the top-level key name is a misnomer
# ~/.aws/credentials, profile iamgc

hive.s3.aws-access-key=ZZ-AWS-ACCESS-KEY-ID
hive.s3.aws-secret-key=ZZ-AWS-SECRET-ACCESS-KEY

# Account role, suitable for Docker
hive.s3.iam-role=arn:aws:iam::ZZ-AWS-USER-ID:role/dev_db_c3_role-iamgc-s3

# -------------------
# lines cribbed from minio setup
hive.s3.path-style-access=true
# hive.s3.endpoint=http://minio:9000
# hive.s3.aws-access-key=minio
# hive.s3.aws-secret-key=minio123

# unclear on the need of the following:
hive.non-managed-table-writes-enabled=true
hive.s3select-pushdown.enabled=true
# hive.storage-format=ORC

# hive.allow-drop-table=true
# -------------------

# Trino connector configs:
#   trino-delta-lake/src/main/java/io/trino/plugin/deltalake/DeltaLakeConfig.java
#   trino-delta-lake/src/main/java/io/trino/plugin/deltalake/metastore/glue/DeltaLakeGlueMetastoreConfig.java
#
# These are not set so as to take their default values

#delta.metadata.cache-ttl=
#delta.metadata.live-files.cache-size=
#delta.domain-compaction-threshold=
#delta.max-outstanding-splits=
#delta.max-splits-per-second=
#delta.max-initial-splits=
#delta.max-initial-split-size=
#delta.max-split-size=
#delta.max-partitions-per-writer=
#delta.enable-non-concurrent-writes=
#delta.default-checkpoint-writing-interval=
#delta.experimental.ignore-checkpoint-write-failures=
#delta.vacuum.min-retention=
#delta.hive-catalog-name=
#delta.checkpoint-row-statistics-writing.enabled=
#delta.table-statistics-enabled=
#delta.extended-statistics.enabled=
#delta.compression-codec=
#delta.hide-non-delta-lake-tables=
